---
layout: post
title: 递归求解
description: 动态规划、贪心算法，以及非确定性计算
category: blog
---

## 求解最短路径


有一整数数组，每个元素表示能前进的步数，求跳出数组的最小步数：

<pre>
input:
1 3 5 2 9 3 4 1 8
output:
1->3->9
</pre>

以上面的数组为例，第一步只能选择 (1)，由于 1 表示下一步只能在后续 1 步范围内选择，因此接下来只能选 (3)，之后可在后续 3 布范围内选择，即 (5 2 9) 中的一个，依次下去，直到跳出数组。要求给出最短的步数及走法。

上例中至少需要 3 步才能出去，不信你可以找找 2 步出去的方法。

这样的问题，最简单（粗暴）的解答就是列举出所有可能的走法，然后从中选出最短的走法。让我们来分析以下这种做法的复杂度：

 1. 形如 $[1\ 1\ 1\ ...]$ 的数组，这样每步都只有一个选择，总共就一种路径，就是从头到尾遍历整个数组，复杂度是 $O(n)$。
 2. 形如 $[2\ 2\ 2\ ...]$ 的数组，这样每步都有2个选择，总共有 $2^n$ 种选择，复杂度为 $O(2^n)$。
 3. 那么，对有 n 个元素的一般形式数组 $[a_0\ a_1\ a_2\ ... a_{n-1}]$，$a_i\geqslant1$，总共有 $$\prod_{i=0}^{n-1} a_i$$ 种选择，复杂度为 $$O(\prod_{i=0}^{n-1} a_i)$$。如果 $a_i=1$ 仅仅为少数情况，复杂度是指数级。
 
如果用图表示各种选择路径，这图就是一棵树：

{:.post-img}
 ![](/assets/images/jump_tree.png)

其中绿色的节点表示能直接跳出去的节点，按上面的暴力解法，整个算法会深度遍历完整棵树，每次到到达叶节点便记录此次从根节点下来的路径，最后计算长度最短的路径。可以改良两点：
 
 1. 遇到绿节点便返回，不用计算余下的词节点之后路径，因为此后的路径总是会更长。
 2. 在遍历的时候使用 current-min 记下当前最短的路径的最后节点及长度，当整个遍历完成之后，直接得到最短路径，无须再次比较路径长度。原理是在一次遍历的时候就保存了有价值的信息，以减少遍历的次数。
 
下面是生成上图的 Javascript 代码，其中 gendot 函数用来生成 dot 源码。这个过程就是这种暴力求解的过程：

{% gist 9967055 %}

在 console 使用 node 执行该代码，并将终端的输出 pipe 到 dot，生成 png 图片。在 vi 中是这样的：
 
```
w || !node % | dot -Tpng -o %.png
```
 
如果你这样解决，当然可以得到答案，但远非最佳。因为效率实在是太低了。原因在于有很多重复的操作，比如图中的节点 9，以它为根节点的子树都有4棵，这样的操作重复了4次，其实只要1次就够了。因为从节点9跳出去的最短路径（可能有多条，但步数相等）永远是一样的。
 
更进一步，如果你仔细观察最短路径 1->3->9，似乎有这样的规律：每个节点都是同一层最大值的节点。难道每次总选择最大的，最后总是能最快跳出去吗？当然，这是一个猜想，需要证明。
 
避免重复计算的思想就是动态规划，而那个猜想就属于贪心算法。算法的核心在于选择（从图中可以明显看出），这篇文章尝试解释为什么以及如何选择，以及选择之间的异同。 
 
## 非确定性计算
 
看着这张图，多条分支，要是能分身该多好。这样每个分身处理一条路径，最后上报谁最短。这样的想法很直观，但并非是瞎想。在计算理论或程序语言中真有这样的东西。以 Scheme 为例，它提供这样一个函数 amb (ambiguous 的缩写)，返回可能的一个答案，然后交给上面判断是否符合要求，如果不行则舍去， amb 接着给出另一个候选答案。
 
非确定性的代码，可以让我们算法看起来更加简洁和清晰:

{% gist 9968337 %}

其中 choose 就是所谓 amb 函数，从一个列表中选一个出来。这段代码看起来没有任何的非尾递归，jump-naive 实质上可以写成迭代函数：

```scheme
(define (jump-naive-loop i)
  (let loop ([n i])
    (loop (select-naive steps n))))
(jump-naive-loop 0)
```

神奇的地方是 choose，它能自己记录分支点，当一个分支结束后，能自动从下一处继续计算。就好像 choose 分化出了好多线程，这些线程分别计算自己的后续路径。

如果计算路径，需要修改 jump 函数，可以使用 stack 保存路径：

```scheme
(define min-steps 99)                                ;; 保存当前最短步数
(define stack (make-parameter '(-1)))                ;; 保存当前路径
(define results (make-parameter '()))                ;; 保存所有路径
(define (jump i)
  (let ((next (select steps i)))
    ;; 保存路径
    (if (<= i (last (stack)))                         ;; 如果当前步要更早，说明已经回溯到上层了，
        (stack (takef (stack) (lambda(x) (<= x i))))  ;; 要清除之前保存的比当前步晚的节点
        (push stack i))                               ;; 判断路径是否比已知的更长，更长则终止分支
    (if (>= (length (stack)) min-steps) (amb)         ;; 终止该分支
        (if (= -1 next)
            (begin
              (push results (stack))                  ;; 结束该分支 save stack
              (set! min-steps (length (stack))))
            (jump next)))))
 
(define (select lst i)
  (let ((rest (drop lst (add1 i)))
        (s (nth lst i)))
    (if (> s (length rest)) -1
        (choose (range (add1 i) (+ (add1 i) s))))))

(with-amb (amb-collect (jump 0)))                     ;; 执行 amb
(pretty-print min-steps)                              ;; 打印最短步数
(pretty-print (results))                              ;; 打印所有的路径，你可以从中选出最短的
```

这里除了保存路径，还对 select 进行了优化，当当前节点可以直接跳出事，使用 (amb) 直接放弃该分支，返回到上层回溯点。amb 函数可使用 call-with-current-continuation (call/cc) 实现，当能迅速判断很多分支不符合条件（迅速死去），使用 amb 非常方便。


## 递归结构分析

递归结构一般有一个特征值，而在最优解问题中，一般由一个数值标志。比如最短的路径的标志就是最短的步数。这个值是我们分析问题的切入点，通过这个值我们能找出子问题：

假设从 $a_{i+1}$ 跳出去的最短步数为 $$s_{i+1}$$，那么从 $a_i$ 跳出去的最短步数 $s_i$ 是多少？

$a_i$ 可选的后续节点为集合：$$\{ a_{i+1} .. a_{i+a_i} \}$$，其中 $a_i$ 为 i 节点的值，因此它们跳出去最短步数为 $$\{ s_{i+1} .. s_{i+a_i} \}$$，那么从 i 跳出去的最短步数就是这个集合中的最小值加1。可表示为：

$$
s_i = \left\{
  \begin{array}{1 1}
    1& \quad \text{$if\quad i=n$}\\
    1+\min_{i<j\le i+a_i}\{s_j\} & \quad \text{$if\quad 0\le i<n$}
  \end{array} \right.\
$$

这便是这个问题的递归结构。首先要找到那个衡量最优解的“值”（这里是步数 $s_i$），然后从那里开始分析。依次便能写出递归算法：

```scheme
;; 构造集合  { i+1,  .. i+a[i] }
(define (r i)
  (let ((n (list-ref steps i)))
    (if (>= (+ i n) (length steps)) (range (add1 i) (length steps))
        (range (add1 i) (+ (add1 i) n)))))
(define (jump-recur i)
  (if (= i (sub1 (length steps))) 0  ;; 最后一个节点能直接跳出去
      (add1 (argmin (lambda(x) x)
                    (map (lambda (j)     ;; 计算 { s[i+1], ... s[i+a[i]]  }
                           (jump-recur j)) (r i))))))
(jump-recur 0)  ;; 3
```

计算出最短的步数是 3.

## 备忘录（memoization）

在上面的递归计算中，计算了很多重复的 (jump-recur i)。对数组 [1 3 5 2 9 3 4 1 8]，比如当 i=1 时，$a_i=3$，会算 { (jump-recur 2), (jump-recur 3), (jump-recur 4) } 中的最小，而当 i=2 时，$a_i=5$，会算{(jump-recur 3), (jump-recur 4), (jump-recur 5), (jump-recur 6), (jump-recur 7)} 中的最小。而 (jump-recur 3), (jump-recur 4) 在 i=1 时算过。

memoization 是 memo 的名词，而不是 memorize 的名词。memoization 专指计算机上的优化技术。通过记录已经算出的结果，来提高下次碰到同样问题的计算速度：将算过的 jump-recur 保存起来，对一个 i 计算前先查查是否算过，如果算过就直接得到结果：

```scheme
(define (jump-recur i)
  (let (memo (loop-up i))
     (if (not (= memo 0)) memo                    ;; 有记录则直接返回
        (if (= i (sub1 (length steps))) 0         ;; 最后一个节点能直接跳出去
             (record (add1 (argmin (lambda(x) x)  ;; 记录并返回结果
                    (map (lambda (j)              ;; 计算 { s[i+1], ... s[i+a[i]] }
                           (jump-recur j)) (r i)))))))))
```

对很多重复计算的情况，这样会大幅提高效率。

## 动态规划

上一节使用 memo 技术去掉不必要的重复计算，还有另外一种于此完全不同的去掉重复计算的方法，这种方法有很大的普世性，叫做动态规划。

“不必要的重复计算”是动态规划的必要条件。那么何为“不必要的重复计算”？最直接的理解就是第一节的图示：存在大量相同子树。

对递归式：

$$
s_i = \left\{
  \begin{array}{1 1}
    1& \quad \text{$if\quad i=n$}\\
    1+\min_{i<j\le i+a_i}\{s_j\} & \quad \text{$if\quad 0\le i<n$}
  \end{array} \right.\
$$

$s_i$ 的计算依赖于 $$\{s_{i+1} ... s_{i+a_i}\}$$。如果 $$s_j,\ s_j \in \{s_{i+1} ... s_{i+a_i}\} $$ 先算出来了，那么很自然地 $$s_i$$ 便能算出来，但这是一般递归问题的结构，问题的关键在于一个子问题如果算出来了，会导致答案的链式反应：存在大量依赖于该子问题的问题父问题有了（全部或者部分）答案，可以想象，这是这样的现象：一个底部的节点亮了，上层的大量节点亮了或者部分地亮了，依次过程，整个节点全亮的速度会非常迅速。但如果是一 般性的递归，每个子问题都是独立的，它们全亮了，它的直接父节点才会亮，这样的收敛速度会慢很多。因此，对能用动态规划解的问题，一般是多项式的复杂度。

因此动态规划的解是 bottom-up 构造出来的。

## 贪心算法

贪心算法是动态规划问题的子集。如果问题的性质满足更多的要求，就能进一步使用更强大（更快）的贪心算法。这个要求便是：每一次局部的最优选择同时也是全局的最优选择。
对递归式的进一步分析：

$$
s_i = \left\{
  \begin{array}{1 1}
    1& \quad \text{$if\quad i=n$}\\
    1+\min_{i<j\le i+a_i}\{s_j\} & \quad \text{$if\quad 0\le i<n$}
  \end{array} \right.\
$$

计算 $s_i$ 对动态规划而言，它说“我要得知道 $\{s_j\}$ 是什么，才能知道哪个最小”，而贪心算法则骄傲地地宣称，我不知道他们是什么，但我依然能作出选择，那就是选眼前最好的，即下一次跳度大的，这样似乎最有可能就跳出去了。

于是递归式一下子便坍塌成了线性的逐次求解过程。

但眼前的贪心选择不能绝对保证最后的结果一定是最右的。除非你能证明。对这个最短步数的问题，确实能证明贪心的眼前选择是最优 的选择：

从节点 i 的后选节点中选一个，如果总是选跳度最远的，那么其他的节点的下一步范围总是包含在这个跳度最远的节点下一步的范围之内。因此如果其中某个节点属于最短路径上的节点，那么，我总能用这个跳度最大的节点代替它。因此它是我最安全的选择。

这样看来，眼前最贪心的选择正是全局最好的选择。

贪心的计算是按照 $ s_0 s_1 .. s\_{n-1}$这样的顺序算下去的，因此它是 top-down 的顺序。


## 总结

都是尝试简化递归式的技巧。一种因为有大量的重复子问题，而采用 bottom-up 能保证迅速收敛到最终答案的构造过程，一种是直接消除了递归，直接 top-down 逐次计算下去得到最终答案。

对面试而言，问题很可能存在贪心的解法，可能是最优的，可能不是。如果不是最优的，那你麻烦了，因为作为面试题，最优解很可能只能枚举出来，即使你使用动态规划，或者其他的办法，复杂度有不一定有显著降低，而且答案还不一定正确。技巧在于，寻找次优的解，而使用贪心的算法，或者简单的解法，说不定效果更好，更重要的是，算法更容易写出 —— 尤其是在面试的时候。

对人的选择而言，有时候贪心算法不一定能得到最优解，但一般得到的都还不错。这是一种退而求其次的智慧。动态规划就是从小处做起，从看起来无关目标的事情 做起，只要你做得够好，一定的积累终究会收敛到你最终的目标：因为大目标都是有相同（而且重复）的小目标组成。要点在于你能很好地对目标划分。
 
 
 
 
 
 
 
 
 
 
 


